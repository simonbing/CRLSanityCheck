{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-06T14:06:43.059448Z",
     "start_time": "2025-01-06T14:06:43.056813Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from crc.eval import compute_multiview_r2\n",
    "from crc.methods.shared import FCEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def construct_invertible_mlp(\n",
    "    n: int = 20,\n",
    "    n_layers: int = 2,\n",
    "    n_iter_cond_thresh: int = 10000,\n",
    "    cond_thresh_ratio: float = 0.25,\n",
    "    weight_matrix_init = \"pcl\",\n",
    "    act_fct = \"leaky_relu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create an (approximately) invertible mixing network based on an MLP.\n",
    "    Based on the mixing code by Hyvarinen et al.\n",
    "\n",
    "    Args:\n",
    "        n: Dimensionality of the input and output data\n",
    "        n_layers: Number of layers in the MLP.\n",
    "        n_iter_cond_thresh: How many random matrices to use as a pool to find weights.\n",
    "        cond_thresh_ratio: Relative threshold how much the invertibility\n",
    "            (based on the condition number) can be violated in each layer.\n",
    "        weight_matrix_init: How to initialize the weight matrices.\n",
    "        act_fct: Activation function for hidden layers.\n",
    "    \"\"\"\n",
    "\n",
    "    class SmoothLeakyReLU(nn.Module):\n",
    "        def __init__(self, alpha=0.2):\n",
    "            super().__init__()\n",
    "            self.alpha = alpha\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.alpha * x + (1 - self.alpha) * torch.log(1 + torch.exp(x))\n",
    "\n",
    "    def get_act_fct(act_fct):\n",
    "        if act_fct == \"relu\":\n",
    "            return torch.nn.ReLU, {}, 1\n",
    "        if act_fct == \"leaky_relu\":\n",
    "            return torch.nn.LeakyReLU, {\"negative_slope\": 0.2}, 1\n",
    "        elif act_fct == \"elu\":\n",
    "            return torch.nn.ELU, {\"alpha\": 1.0}, 1\n",
    "        elif act_fct == \"max_out\":\n",
    "            raise NotImplementedError\n",
    "        elif act_fct == \"smooth_leaky_relu\":\n",
    "            return SmoothLeakyReLU, {\"alpha\": 0.2}, 1\n",
    "        elif act_fct == \"softplus\":\n",
    "            return torch.nn.Softplus, {\"beta\": 1}, 1\n",
    "        else:\n",
    "            raise Exception(f\"activation function {act_fct} not defined.\")\n",
    "\n",
    "    layers = []\n",
    "    act_fct, act_kwargs, act_fac = get_act_fct(act_fct)\n",
    "\n",
    "    # Subfuction to normalize mixing matrix\n",
    "    def l2_normalize(Amat, axis=0):\n",
    "        # axis: 0=column-normalization, 1=row-normalization\n",
    "        l2norm = np.sqrt(np.sum(Amat * Amat, axis))\n",
    "        Amat = Amat / l2norm\n",
    "        return Amat\n",
    "\n",
    "    condList = np.zeros([n_iter_cond_thresh])\n",
    "    if weight_matrix_init == \"pcl\":\n",
    "        for i in range(n_iter_cond_thresh):\n",
    "            A = np.random.uniform(-1, 1, [n, n])\n",
    "            A = l2_normalize(A, axis=0)\n",
    "            condList[i] = np.linalg.cond(A)\n",
    "        condList.sort()  # Ascending order\n",
    "    condThresh = condList[int(n_iter_cond_thresh * cond_thresh_ratio)]\n",
    "    # print(\"condition number threshold: {0:f}\".format(condThresh))\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        lin_layer = nn.Linear(n, n, bias=False)\n",
    "\n",
    "        if weight_matrix_init == \"pcl\":\n",
    "            condA = condThresh + 1\n",
    "            while condA > condThresh:\n",
    "                weight_matrix = np.random.uniform(-1, 1, (n, n))\n",
    "                weight_matrix = l2_normalize(weight_matrix, axis=0)\n",
    "\n",
    "                condA = np.linalg.cond(weight_matrix)\n",
    "                # print(\"    L{0:d}: cond={1:f}\".format(i, condA))\n",
    "            # print(f\"layer {i+1}/{n_layers},  condition number: {np.linalg.cond(weight_matrix)}\")\n",
    "            lin_layer.weight.data = torch.tensor(weight_matrix, dtype=torch.float32)\n",
    "\n",
    "        elif weight_matrix_init == \"rvs\":\n",
    "            weight_matrix = ortho_group.rvs(n)\n",
    "            lin_layer.weight.data = torch.tensor(weight_matrix, dtype=torch.float32)\n",
    "        elif weight_matrix_init == \"expand\":\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception(f\"weight matrix {weight_matrix_init} not implemented\")\n",
    "\n",
    "        layers.append(lin_layer)\n",
    "\n",
    "        if i < n_layers - 1:\n",
    "            layers.append(act_fct(**act_kwargs))\n",
    "\n",
    "    mixing_net = nn.Sequential(*layers)\n",
    "\n",
    "    # fix parameters\n",
    "    for p in mixing_net.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    return mixing_net"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T14:03:43.232874Z",
     "start_time": "2025-01-06T14:03:43.227278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T13:59:43.478094Z",
     "start_time": "2025-01-06T13:59:43.475568Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Generate synthetic samples\n",
    "z = rs.normal(size=(5000, 5))\n",
    "content_indices = ((0, 1, 2), (2, 4), (0, 3))\n",
    "subsets = ((0, 1), (0, 2), (0, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T13:59:44.264098Z",
     "start_time": "2025-01-06T13:59:44.261298Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Sample encoders\n",
    "# enc_view_0 = FCEncoder(in_dim=5, latent_dim=5, hidden_dims=[5, 5, 5])\n",
    "# enc_view_1 = FCEncoder(in_dim=3, latent_dim=3, hidden_dims=[3, 3, 3])\n",
    "# enc_view_2 = FCEncoder(in_dim=2, latent_dim=2, hidden_dims=[2, 2, 2])\n",
    "# enc_view_3 = FCEncoder(in_dim=2, latent_dim=2, hidden_dims=[2, 2, 2])\n",
    "\n",
    "enc_view_0 = construct_invertible_mlp(n=5, n_layers=3, n_iter_cond_thresh=25000, cond_thresh_ratio=0.001)\n",
    "enc_view_1 = construct_invertible_mlp(n=3, n_layers=3, n_iter_cond_thresh=25000, cond_thresh_ratio=0.001)\n",
    "enc_view_2 = construct_invertible_mlp(n=2, n_layers=3, n_iter_cond_thresh=25000, cond_thresh_ratio=0.001)\n",
    "enc_view_3 = construct_invertible_mlp(n=2, n_layers=3, n_iter_cond_thresh=25000, cond_thresh_ratio=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T14:06:51.172118Z",
     "start_time": "2025-01-06T14:06:49.783355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Apply known bijective mixing function\n",
    "z_0 = enc_view_0(torch.as_tensor(z[:, [0, 1, 2, 3, 4]], dtype=torch.float32)).detach().numpy()\n",
    "z_1 = enc_view_1(torch.as_tensor(z[:, [0, 1, 2]], dtype=torch.float32)).detach().numpy()\n",
    "z_2 = enc_view_2(torch.as_tensor(z[:, [2, 4]], dtype=torch.float32)).detach().numpy()\n",
    "z_3 = enc_view_3(torch.as_tensor(z[:, [0, 3]], dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "# z_hat = np.stack((z_0, z_1, z_2, z_3))\n",
    "z_hat = [z_0, z_1, z_2, z_3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T14:06:57.438867Z",
     "start_time": "2025-01-06T14:06:57.431194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 5000, 5)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hat.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T13:56:58.837885Z",
     "start_time": "2025-01-06T13:56:58.835082Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "r2_dict = compute_multiview_r2(z, z_hat, content_indices, subsets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T14:07:51.365329Z",
     "start_time": "2025-01-06T14:07:04.865877Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.98486829, 0.49067374, 0.98795771],\n       [0.98537678, 0.48947362, 0.49063802],\n       [0.98200491, 0.98644503, 0.48718567],\n       [0.48453301, 0.47914021, 0.98828493],\n       [0.48647658, 0.98535909, 0.48682604]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_dict['avg_r2_nonlin']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T14:07:56.004685Z",
     "start_time": "2025-01-06T14:07:56.001087Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.82736308, 0.39745582, 0.89062949],\n       [0.77091651, 0.34900836, 0.36456917],\n       [0.77459848, 0.76888531, 0.36426642],\n       [0.37297095, 0.37443435, 0.75907766],\n       [0.39454757, 0.76619026, 0.39784204]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_dict['avg_r2_lin']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T14:09:33.228475Z",
     "start_time": "2025-01-06T14:09:33.222819Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.99314519,         nan,         nan],\n       [ 0.98885679,         nan,         nan],\n       [ 0.98827947,         nan,         nan],\n       [-0.0036829 ,         nan,         nan],\n       [-0.00570299,         nan,         nan]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_dict['r2_nonlin'][..., 1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T14:49:39.152824Z",
     "start_time": "2025-01-06T14:49:39.082357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
